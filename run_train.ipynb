{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PROJECT: Task 2: Toxic Span Detection (Sequence Labeling)"
      ],
      "metadata": {
        "id": "Uc1Vhkm-ei_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Sai Chaitanya Pachipulusu\n",
        "Stevens ID: 20011257"
      ],
      "metadata": {
        "id": "puYF8HJwejDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries:"
      ],
      "metadata": {
        "id": "OBxj4leUepiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Ye_6jfEy0KWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcbcf4af-df92-4ad1-acab-d5f4c4604bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.6.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.12.0)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.20.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.28.1)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.5.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (5.3.0)\n",
            "Requirement already satisfied: nbclassic in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (0.5.6)\n",
            "Requirement already satisfied: jupyter-server-ydoc~=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (1.24.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (6.4.8)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (6.2)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: jupyterlab-server~=2.19 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (2.22.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-ydoc~=0.2.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->-r requirements.txt (line 1)) (0.2.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.12.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (23.3.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.54.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.12.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (16.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->-r requirements.txt (line 6)) (2.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (2.29.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->-r requirements.txt (line 7)) (2023.4.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->-r requirements.txt (line 5)) (0.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.1->jupyterlab->-r requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (21.3.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (1.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (5.7.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (3.6.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (6.1.12)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (5.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.17.1)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (6.5.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: jupyter-server-fileid<1,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: ypy-websocket<0.9.0,>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: y-py<0.6.0,>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-ydoc~=0.2.3->jupyterlab->-r requirements.txt (line 1)) (0.5.9)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (0.9.11)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (2.12.1)\n",
            "Requirement already satisfied: jsonschema>=4.17.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (4.17.3)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab->-r requirements.txt (line 1)) (1.5.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab->-r requirements.txt (line 1)) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook<7->jupyterlab->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 7)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 7)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (2.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (2.14.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (0.1.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (3.0.38)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (0.18.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyterlab->-r requirements.txt (line 1)) (4.8.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic->jupyterlab->-r requirements.txt (line 1)) (0.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->jupyterlab->-r requirements.txt (line 1)) (0.8.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (0.19.3)\n",
            "Requirement already satisfied: jupyter-events>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (0.6.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.7.4)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (4.9.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (4.11.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (2.16.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->jupyterlab->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyterlab->-r requirements.txt (line 1)) (0.2.6)\n",
            "Requirement already satisfied: aiofiles<23,>=22.1.0 in /usr/local/lib/python3.10/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (22.1.0)\n",
            "Requirement already satisfied: aiosqlite<1,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (0.19.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (21.2.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (0.1.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.5.0->jupyter-server-fileid<1,>=0.6.0->jupyter-server-ydoc~=0.8.0->jupyterlab->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab->-r requirements.txt (line 1)) (2.21)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (1.13)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (20.11.0)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (1.5.1)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (2.3)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server~=2.19->jupyterlab->-r requirements.txt (line 1)) (1.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIjnvBEJVsXk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import nltk\n",
        "from typing import List, Tuple, Union\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import random\n",
        "import torch\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn import Module, ReLU, Linear, Sigmoid, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel, TFBertModel\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7_j2R3qDih2",
        "outputId": "94eefdfd-0a4b-4ebd-be82-c0536f273b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading:"
      ],
      "metadata": {
        "id": "W-HL5sEJLEx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('tsd_train.csv')\n",
        "test_data = pd.read_csv('tsd_test.csv')"
      ],
      "metadata": {
        "id": "1eJ1F9PWoamG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape od Training Data: \", train_data.shape)\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYEQ388To0sI",
        "outputId": "d2291ab7-f49f-478f-c64a-65d83d64fc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape od Training Data:  (7939, 2)\n",
            "                                               spans  \\\n",
            "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
            "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
            "2                                       [0, 1, 2, 3]   \n",
            "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
            "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
            "\n",
            "                                                text  \n",
            "0  Another violent and aggressive immigrant killi...  \n",
            "1  I am 56 years old, I am not your fucking junio...  \n",
            "2                  Damn, a whole family. Sad indeed.  \n",
            "3  What a knucklehead. How can anyone not know th...  \n",
            "4  \"who do you think should do the killing?\"\\n\\nA...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of Testing Data: \", test_data.shape)\n",
        "print(test_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFyh6S4ZMv_k",
        "outputId": "db8b0c05-83a3-4d29-a39b-c3b0575eae89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Testing Data:  (2000, 2)\n",
            "                                               spans  \\\n",
            "0  [84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135...   \n",
            "1                           [81, 82, 83, 84, 85, 86]   \n",
            "2                                                 []   \n",
            "3                                                 []   \n",
            "4                                                 []   \n",
            "\n",
            "                                                text  \n",
            "0  That's right. They are not normal. And I am st...  \n",
            "1  \"Watch people die from taking away their healt...  \n",
            "2  tens years ago i contacted the PDR and suggest...  \n",
            "3  The parallels between the ANC and the Sicilian...  \n",
            "4  Intel Community: â€˜How can we work for a Presid...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning:\n",
        "\n",
        "- Data is clean. It does not have any null values/empty values."
      ],
      "metadata": {
        "id": "6RSMXH0WLhIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isnull().sum(axis=0))\n",
        "print(test_data.isnull().sum(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaIV6ecIzqpK",
        "outputId": "8beea42f-8f58-4d5b-9524-93483b0cb954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spans    0\n",
            "text     0\n",
            "dtype: int64\n",
            "spans    0\n",
            "text     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-processing"
      ],
      "metadata": {
        "id": "S_qI_ntBLLXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Converting the spans columns from string to valid lists."
      ],
      "metadata": {
        "id": "UadCoJ8OLxQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"spans\"] = [ast.literal_eval(x) for x in train_data[\"spans\"]]\n",
        "test_data[\"spans\"] = [ast.literal_eval(x) for x in test_data[\"spans\"]]"
      ],
      "metadata": {
        "id": "lEVXm3i_fsyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empty_spans_train, empty_spans_test = 0, 0\n",
        "for i in train_data[\"spans\"]:\n",
        "  if len(i) == 0:\n",
        "    empty_spans_train += 1\n",
        "print(\"Number of empty spans in train: \", empty_spans_train)\n",
        "\n",
        "for i in test_data[\"spans\"]:\n",
        "  if len(i) == 0:\n",
        "    empty_spans_test += 1\n",
        "print(\"Number of empty spans in test: \", empty_spans_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDVcSA_9L-rX",
        "outputId": "b45d3612-2b98-4cf6-e06f-99f0a1264c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of empty spans in train:  485\n",
            "Number of empty spans in test:  394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_spans(data_text, data_span):\n",
        "    spans_new = []\n",
        "    for idx in range(len(data_text)):\n",
        "      sentence = []\n",
        "      start = None\n",
        "      for idx_arr in range(len(data_span[idx])):\n",
        "        if start is None or data_span[idx][idx_arr] != data_span[idx][idx_arr-1] + 1:\n",
        "          if start is not None:\n",
        "            sentence.append(data_text[idx][start:data_span[idx][idx_arr-1]+1])\n",
        "          start = data_span[idx][idx_arr]\n",
        "      if start is not None:\n",
        "        sentence.append(data_text[idx][start:data_span[idx][-1]+1])\n",
        "      spans_new.append(sentence)\n",
        "    return spans_new"
      ],
      "metadata": {
        "id": "nxQXqKeifqo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_spans_new = new_spans(train_data[\"text\"], train_data[\"spans\"])\n",
        "test_spans_new = new_spans(test_data[\"text\"], test_data[\"spans\"])"
      ],
      "metadata": {
        "id": "3FwFQ39uhS4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "sazv8q2fxehk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_2_tokens(text):\n",
        "  text = nlp(text)\n",
        "  text_tokens = []\n",
        "  for token in text:\n",
        "      text_subtokens = tokenizer.tokenize(token.text)\n",
        "      text_tokens += text_subtokens\n",
        "  return text_tokens"
      ],
      "metadata": {
        "id": "_ix2-DWO3uD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_tokens, test_text_tokens = [], []\n",
        "for idx in range(len(train_data)):\n",
        "  train_text_token = text_2_tokens(train_data[\"text\"][idx])\n",
        "  train_text_tokens.append(train_text_token)\n",
        "\n",
        "for idx in range(len(test_data)):\n",
        "  test_text_token = text_2_tokens(test_data[\"text\"][idx])\n",
        "  test_text_tokens.append(test_text_token)"
      ],
      "metadata": {
        "id": "y-bzHEjU3uFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_tokens(tokens, text, spans):\n",
        "  token_idx = []\n",
        "  start, end = 0, 0\n",
        "  for token in tokens:\n",
        "    sent = text.lower()\n",
        "    token = token.strip('#')\n",
        "    start = sent.find(token, start)\n",
        "    end = start + len(token)\n",
        "    token_idx.append((start,end))\n",
        "    start = end\n",
        "\n",
        "  toxic_words = []\n",
        "  for word, (start,end) in zip(tokens, token_idx):\n",
        "    k = [i for i in range(start,end)]\n",
        "    if any(i in spans for i in k):\n",
        "      toxic_words.append(1)\n",
        "    else:\n",
        "      toxic_words.append(0)\n",
        "\n",
        "  return toxic_words"
      ],
      "metadata": {
        "id": "oaa1JdvGWoTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_binary_train = []\n",
        "for idx in range(len(train_data)):\n",
        "  toxic_words = bin_tokens(train_text_tokens[idx], train_data[\"text\"][idx], train_data[\"spans\"][idx])\n",
        "  toxic_binary_train.append(toxic_words)"
      ],
      "metadata": {
        "id": "GwPEpLAiXdFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = max([len(x) for x in train_text_tokens])\n",
        "print(maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHaGG66s3uK1",
        "outputId": "76d4e769-259c-4a55-a18f-62496c9e19ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(70)\n",
        "torch.manual_seed(70)"
      ],
      "metadata": {
        "id": "4cyCXn46-Gex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2306fa0e-71e3-490e-c8f9-439d6242ae44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7efcd50f56d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens1 = [['[CLS]'] + t[:maxlen - 2] + ['[SEP]'] for t in train_text_tokens]\n",
        "test_tokens = [['[CLS]'] + t[:maxlen - 2] + ['[SEP]'] for t in test_text_tokens]\n",
        "\n",
        "print(len(train_tokens1), len(test_tokens))\n",
        "print(\"Train tokens:\", train_tokens1[0:2])\n",
        "print(\"Test tokens:\", test_tokens[0:2])"
      ],
      "metadata": {
        "id": "jbjpGDdu-GiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcadb894-b67d-4a2c-f819-0a972c678742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7939 2000\n",
            "Train tokens: [['[CLS]', 'another', 'violent', 'and', 'aggressive', 'immigrant', 'killing', 'a', 'innocent', 'and', 'intelligent', 'us', 'citizen', '.', '.', '.', '.', 'sarcasm', '[SEP]'], ['[CLS]', 'i', 'am', '56', 'years', 'old', ',', 'i', 'am', 'not', 'your', 'fucking', 'junior', 'pal', '.', 'what', 'you', 'are', 'saying', 'makes', 'no', 'sense', '.', 'i', 'do', 'n', \"'\", 't', 'know', 'what', 'you', 'are', 'basin', '##g', 'this', 'on', '.', 'the', 'cheap', 'black', 'market', 'crap', 'is', 'still', 'coming', 'up', 'from', 'mexican', 'nationals', ',', 'and', 'the', 'good', 'stuff', 'from', 'bc', 'and', 'hum', '##bolt', '.', 'the', 'i', '##5', 'corridor', 'is', 'still', 'just', 'as', 'busy', ',', 'and', 'they', 'are', 'still', 'making', 'a', 'ton', 'of', 'money', '.', 'nothing', 'has', 'really', 'changed', 'except', 'that', 'the', 'legal', 'market', 'has', 'made', 'it', 'easy', 'for', 'anyone', 'of', 'legal', 'age', 'to', 'buy', 'it', '.', 'and', 'the', 'legal', 'market', 'is', 'controlled', 'by', 'corporate', 'grow', '##ers', 'with', 'million', 'dollar', 'facilities', ',', 'or', 'a', 'co', '-', 'op', 'of', 'smaller', 'grow', '##ers', '.', 'the', 'federal', 'government', '\"', 'war', 'on', 'drugs', '\"', 'really', 'has', 'no', 'impact', 'on', 'the', 'legal', 'market', 'in', 'oregon', '.', 'i', 'do', 'n', \"'\", 't', 'see', 'any', 'g', '##lu', '##tton', 'of', 'weed', ',', 'whatever', 'that', 'means', '.', '[SEP]']]\n",
            "Test tokens: [['[CLS]', 'that', \"'\", 's', 'right', '.', 'they', 'are', 'not', 'normal', '.', 'and', 'i', 'am', 'starting', 'from', 'the', 'premise', 'that', 'they', 'are', 'abnormal', '.', 'proceed', 'w', '##th', 'the', 'typical', 'racist', ',', 'big', '##ot', ',', 'sex', '##ist', 'rubbish', '.', 'thanks', '!', '[SEP]'], ['[CLS]', '\"', 'watch', 'people', 'die', 'from', 'taking', 'away', 'their', 'healthcare', '\"', 'ding', 'ding', 'ding', '!', 'winner', 'of', 'stupid', 'post', 'of', 'the', 'day', 'award', '!', '[SEP]']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_tokens(tokens, max_len=maxlen):\n",
        "    length = len(tokens)\n",
        "    pad_length = max_len - length\n",
        "    if pad_length < 0:\n",
        "        pad_length = 0\n",
        "    \n",
        "    tokens += [0] * pad_length                                 # pad tokens with zeros if necessary\n",
        "    \n",
        "    if length > max_len:                                       # truncate tokens if necessary\n",
        "        tokens = tokens[:max_len]\n",
        "    \n",
        "    mask = [1] * length + [0] * pad_length                     # create attention mask to indicate which tokens are padding (0) and which are not (1)\n",
        "\n",
        "    tokens = np.array(tokens, dtype=\"int\")\n",
        "    mask = np.array(mask, dtype=\"int\")\n",
        "    \n",
        "    return tokens, mask"
      ],
      "metadata": {
        "id": "EFeYTllm-z45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_ids_and_masks(text_tokens):\n",
        "    token_ids, masks = [], []\n",
        "\n",
        "    for token in text_tokens:\n",
        "        tokens, mask = pad_tokens(tokenizer.convert_tokens_to_ids(token), maxlen)\n",
        "        token_ids.append(tokens)\n",
        "        masks.append(mask)\n",
        "\n",
        "    return np.array(token_ids), np.array(masks)\n",
        "\n",
        "tr_token_ids, tr_masks = token_ids_and_masks(train_tokens1)\n",
        "te_token_ids, te_masks = token_ids_and_masks(test_tokens)"
      ],
      "metadata": {
        "id": "0pit0ILk-z7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_labels = [[0] + arr[:maxlen - 2] + [0] for arr in toxic_binary_train]\n",
        "\n",
        "train_labels1 = []\n",
        "for label in train_text_labels:\n",
        "\n",
        "    if len(label) >= maxlen:                            # Truncate or pad the label to the desired length\n",
        "        label = label[:maxlen]\n",
        "    else:\n",
        "        label += [0] * (maxlen - len(label))\n",
        "\n",
        "    label = [value for value in label]                  # Convert to a array\n",
        "    train_labels1.append(label)\n"
      ],
      "metadata": {
        "id": "lGud4gzvSKUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Validation\n",
        "# dataframe - spans, text, toxic_phrases_train, train_text_tokens -> train_tokens -> (tr_token_ids, tr_masks), toxic_binary_train -> train_text_labels -> train_labels1, train_tokens -> train_split_tokens\n",
        "# spans, text, toxic_phrases_train, tr_token_ids, tr_masks, train_labels, train_split_tokens   =====> train and valid\n",
        "\n",
        "#Testing\n",
        "# dataframe - spans, text, test_text_tokens -> test_tokens -> (te_token_ids, te_masks), toxic_binary_test -> test_text_labels -> test_labels\n",
        "# spans, text, te_token_ids, te_masks, test_labels"
      ],
      "metadata": {
        "id": "jJ89N3l3Ga7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_ratio = 0.15\n",
        "\n",
        "train_spans, valid_spans, train_text, valid_text, train_token_ids, valid_token_ids, train_masks, valid_masks, train_labels, valid_labels , train_tokens, valid_tokens \\\n",
        "= train_test_split(train_data[\"spans\"].tolist(), train_data[\"text\"].tolist(), tr_token_ids, tr_masks, train_labels1, train_tokens1, test_size=valid_ratio, random_state=42)"
      ],
      "metadata": {
        "id": "OkRjRzBxEdHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(Module):\n",
        "  \n",
        "    def __init__(self, hidden_units):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.hidden_layer = Linear(BertModel.from_pretrained('bert-base-uncased').config.hidden_size, hidden_units)\n",
        "        self.activation = ReLU()\n",
        "        self.out = Linear(hidden_units, 1)\n",
        "        self.final_activation = Sigmoid()\n",
        "\n",
        "    def forward(self, input, mask, labels=None):\n",
        "        outputs = self.bert(input_ids=input, attention_mask=mask)          # Inputs are passed to bert model\n",
        "        hid_layer_output = self.hidden_layer(outputs.last_hidden_state)    # Outputs of the last hidden state are the inputs to the next hidden state\n",
        "        activation_output = self.activation(hid_layer_output)              # Those outputs are send through activation layer (ReLU)\n",
        "        output_layer = self.out(activation_output)                         # Output from the Linear layer\n",
        "        final_output = self.final_activation(output_layer)                 # This is paased through final activation function (sigmoid)\n",
        "\n",
        "        bce_loss = BCELoss()\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = bce_loss(final_output, labels.float())\n",
        "            \n",
        "        return loss, final_output\n",
        "\n",
        "hidden_units = 32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertClassifier(hidden_units).to(device)\n"
      ],
      "metadata": {
        "id": "0OILFanXScTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91c1feb-b2cc-41c8-fb48-4d6ce0909fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary\n",
        "# import torchvision.models as models\n",
        "# summary(model, input_size, batch_size=-1, device='cuda')"
      ],
      "metadata": {
        "id": "ecwW9lcSw-gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "with open('network.txt', 'w') as f:\n",
        "    sys.stdout = f\n",
        "    summary(model, input_size, device=device.type)\n",
        "    sys.stdout = sys.__stdout__"
      ],
      "metadata": {
        "id": "wwwRqsXTUide"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "# Generate the summary and save it to \"network.txt\"\n",
        "input_size = (1, 512)  # Adjust the input size according to your model input\n",
        "with open(\"network.txt\", \"w\") as f:\n",
        "    summary(model, input_size, device=device.type, file=f)\n"
      ],
      "metadata": {
        "id": "XkSZthbmxl53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary\n",
        "\n",
        "# with open(\"network.txt\", \"w\") as f:\n",
        "#     summary(model, (6748, 336,)) # Replace input_size with the size of your input\n",
        "#     f.write(str(summary))"
      ],
      "metadata": {
        "id": "-bB4gIAvaBfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (torch.tensor(train_token_ids)).size()\n",
        "# (torch.tensor(train_masks)).size()\n",
        "# train_dataset.shape"
      ],
      "metadata": {
        "id": "Q9OJjKZOkq4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "TUaQTsmsScEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56478e1c-e978-40f0-c43d-79b972538f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertClassifier(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (hidden_layer): Linear(in_features=768, out_features=32, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (final_activation): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    torch.tensor(train_token_ids),\n",
        "    torch.tensor(train_masks),\n",
        "    torch.tensor(train_labels))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "valid_dataset = TensorDataset(\n",
        "    torch.tensor(valid_token_ids),\n",
        "    torch.tensor(valid_masks),\n",
        "    torch.tensor(valid_labels))\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "test_dataset = TensorDataset(torch.tensor(te_token_ids), torch.tensor(te_masks))\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "izjIWRW-Sbz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model.parameters(), lr=3e-6)"
      ],
      "metadata": {
        "id": "6zGtorkHSKYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "loss = BCELoss()\n",
        "total_len = len(train_token_ids)\n",
        "valid_len = len(valid_token_ids)\n",
        "epoch_train_loss = []\n",
        "epoch_valid_loss = []\n",
        "for epoch_num in range(EPOCHS):\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    model.train()\n",
        "    for step, batch_data in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        labels = labels.unsqueeze(-1)                                            # make labels shape similar to output shape before passing to loss. labels- (batch_size x sequence length x 1)\n",
        "\n",
        "        loss, _ = model(token_ids, masks, labels)                                # token_ids, masks, labels = all are of size (batch_size x sequence length)\n",
        "\n",
        "        train_loss = loss.item()\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "    epoch_train_loss.append(np.mean(train_losses))\n",
        "\n",
        "    model.eval()                                                                 # switch the model to evaluation mode\n",
        "    with torch.no_grad():                                                        # temporarily disable gradient calculations within the for loop\n",
        "        for step1, batch_data1 in enumerate(tqdm(valid_dataloader)):\n",
        "            token_ids1, masks1, labels1 = tuple(t.to(device) for t in batch_data1)\n",
        "            labels1 = labels1.unsqueeze(-1)  \n",
        "            valid_loss, _ = model(token_ids1, masks1, labels1)\n",
        "            valid_losses.append(valid_loss.item())\n",
        "\n",
        "    epoch_valid_loss.append(np.mean(valid_losses))\n",
        "\n",
        "    print(f'\\nEpoch {epoch_num + 1} / {EPOCHS} - train loss: {epoch_train_loss[-1] :.4f} - valid loss: {epoch_valid_loss[-1] :.4f}')"
      ],
      "metadata": {
        "id": "H4oV0eOP8qBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ef3c6b-92da-4e1f-8d32-be7b24df7537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [07:13<00:00,  1.95it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:26<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 / 3 - train loss: 0.0758 - valid loss: 0.0368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [07:11<00:00,  1.95it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:26<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 / 3 - train loss: 0.0358 - valid loss: 0.0333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [07:11<00:00,  1.96it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:26<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 / 3 - train loss: 0.0323 - valid loss: 0.0319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "xFgb47EMCYy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "id": "WYhSwt-5CeLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS1 = [1,2,3]\n",
        "plt.plot(EPOCHS1, epoch_train_loss, 'b', label = 'Training loss')\n",
        "plt.plot(EPOCHS1, epoch_valid_loss, 'r', label = 'Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "M4uX6lgoUgUM",
        "outputId": "2f7d0838-2741-412f-8f83-19f925496e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUoElEQVR4nO3deVxU9f7H8dcAsimLubAUYqapmWK5EHpLKwrNa9EmmimZtpiaZlmauZS/rnbTtNLcrluZS1Z6u2aaknpNKcsltau2XBcq0cwEQUVlzu+Pc5mcZGfgzMD7+XjMg8OZ75z5fBuIt+d8z/drMwzDQERERKQK8bK6ABEREZGKpgAkIiIiVY4CkIiIiFQ5CkAiIiJS5SgAiYiISJWjACQiIiJVjgKQiIiIVDk+Vhfgjux2O7/88gtBQUHYbDaryxEREZFiMAyDU6dOERkZiZdX4ed4FIDy8csvvxAVFWV1GSIiIlIKaWlpXHHFFYW2UQDKR1BQEGD+BwwODra4GhERESmOzMxMoqKiHH/HC6MAlI+8y17BwcEKQCIiIh6mOMNXNAhaREREqhwFIBEREalyFIBERESkytEYIBERKXe5ubmcP3/e6jLEw1WrVg1vb2+XHEsBSEREyo1hGKSnp3Py5EmrS5FKIjQ0lPDw8DLP06cAJCIi5SYv/NStW5fAwEBNLiulZhgGp0+f5tixYwBERESU6XgKQCIiUi5yc3Md4adWrVpWlyOVQEBAAADHjh2jbt26ZbocpkHQIiJSLvLG/AQGBlpciVQmeT9PZR1TpgAkIiLlSpe9xJVc9fOkACQiIiJVjgKQiIiIVDkKQCIiIhWgfv36TJkypdjtN2zYgM1mK/cpBObPn09oaGi5voc7UgCqYGvWQE6O1VWIiEhBbDZboY+xY8eW6rhfffUVjz76aLHbt2vXjiNHjhASElKq95PC6Tb4CjRyJPztb/DUU/Daa1ZXIyIi+Tly5Ihje+nSpYwePZr9+/c79tWoUcOxbRgGubm5+PgU/ee0Tp06JarD19eX8PDwEr1Gik9ngCrQDTeYXydPhpUrra1FRMQKhgHZ2dY8DKN4NYaHhzseISEh2Gw2x/f79u0jKCiITz75hFatWuHn58fnn3/Ojz/+yF133UVYWBg1atSgTZs2rFu3zum4f74EZrPZ+Mc//sHdd99NYGAgjRo14qOPPnI8/+dLYHmXqtasWUPTpk2pUaMGnTp1cgpsFy5c4MknnyQ0NJRatWrx3HPPkZycTGJiYok+p+nTp3PVVVfh6+tL48aNeeeddy76DA3Gjh1LvXr18PPzIzIykieffNLx/FtvvUWjRo3w9/cnLCyM++67r0TvXVEUgCpQ164weLC5nZwMP/1kbT0iIhXt9GmoUcOax+nTruvH8OHDmTBhAnv37qVFixZkZWVxxx13kJKSwo4dO+jUqRNdu3bl8OHDhR7nxRdfpFu3buzatYs77riDnj17cuLEiUL++51m4sSJvPPOO/z73//m8OHDPPPMM47nX3nlFd59913mzZvH5s2byczMZMWKFSXq2/Llyxk8eDBPP/00e/bs4bHHHqNPnz6sX78egA8++IDJkyczc+ZMvv/+e1asWEHz5s0B+Prrr3nyySd56aWX2L9/P6tXr+amm24q0ftXGEMukZGRYQBGRkaGy4999qxhXH+9YYBh3HijYZw/7/K3EBFxC2fOnDH+85//GGfOnHHsy8oy//9nxSMrq+R9mDdvnhESEuL4fv369QZgrFixosjXNmvWzHjzzTcd30dHRxuTJ092fA8YL7zwwkX/bbIMwPjkk0+c3uv333931AIYP/zwg+M106ZNM8LCwhzfh4WFGa+++qrj+wsXLhj16tUz7rrrrmL3sV27dsYjjzzi1Ob+++837rjjDsMwDGPSpEnG1VdfbZw7d+6SY33wwQdGcHCwkZmZWeD7lVV+P1d5SvL3W2eAKpifHyxdCkFBsGkTjBtndUUiIhUnMBCysqx5uHJC6tatWzt9n5WVxTPPPEPTpk0JDQ2lRo0a7N27t8gzQC1atHBsV69eneDgYMdaV/kJDAzkqquucnwfERHhaJ+RkcHRo0dp27at43lvb29atWpVor7t3buX9u3bO+1r3749e/fuBeD+++/nzJkzNGjQgEceeYTly5dz4cIFAG677Taio6Np0KABvXr14t133+W0K0+9uZACkAUaNoSZM83tcePgf2cVRUQqPZsNqle35uHKCamrV6/u9P0zzzzD8uXL+dvf/samTZvYuXMnzZs359y5c4Uep1q1an/672PDbreXqL1R3MFNLhIVFcX+/ft56623CAgI4IknnuCmm27i/PnzBAUFsX37dhYvXkxERASjR48mJiam3G/lLw0FIIv06AEPP2yemO3ZEwoJ/CIi4uY2b97MQw89xN13303z5s0JDw/n4MGDFVpDSEgIYWFhfPXVV459ubm5bN++vUTHadq0KZs3b3bat3nzZq655hrH9wEBAXTt2pU33niDDRs2kJqayu7duwHw8fEhPj6ev//97+zatYuDBw/y2WeflaFn5UO3wVvojTcgNRX27jUHRX/8MXgpkoqIeJxGjRrx4Ycf0rVrV2w2G6NGjSr0TE55GTRoEOPHj6dhw4Y0adKEN998k99//71E62cNGzaMbt26cd111xEfH8+//vUvPvzwQ8ddbfPnzyc3N5fY2FgCAwNZuHAhAQEBREdHs3LlSv773/9y0003UbNmTVatWoXdbqdx48bl1eVS059bC1WvDu+9B/7+sHq15gYSEfFUr732GjVr1qRdu3Z07dqVhIQErr/++gqv47nnnqNHjx707t2buLg4atSoQUJCAv7+/sU+RmJiIq+//joTJ06kWbNmzJw5k3nz5tGxY0cAQkNDmT17Nu3bt6dFixasW7eOf/3rX9SqVYvQ0FA+/PBDbrnlFpo2bcqMGTNYvHgxzZo1K6cel57NqOiLhx4gMzOTkJAQMjIyCA4OLvf3mzULHnsMfHzg888hNrbc31JEpNydPXuWAwcOcOWVV5boD7C4jt1up2nTpnTr1o1xleSum8J+rkry91tngNzAI4/A/ffDhQvQvTu44VgxERHxAIcOHWL27Nl899137N69m/79+3PgwAEeeOABq0tzOwpAbsBmg9mz4cor4eBBMxDpvJyIiJSUl5cX8+fPp02bNrRv357du3ezbt06mjZtanVpbkeDoN1ESAgsWQLt28P77/9xWUxERKS4oqKiLrmDS/KnM0BupG1bmDDB3B4yBP53R6GIiIi4mAKQm3nqKejcGc6ehW7dzAX8RERExLUUgNyMlxcsWACRkbBvHwwaZHVFIiIilY8CkBuqUwfefdcMQ/PmmdsiIiLiOgpAbqpjRxg1ytx+/HH4/ntLyxEREalUFIDc2AsvwE03masYd+8OOTlWVyQiIsXVsWNHhgwZ4vi+fv36TJkypdDX2Gw2VqxYUeb3dtVxCjN27FhatmxZru9RnhSA3JiPDyxaBLVqwfbt8OyzVlckIlL5de3alU6dOuX73KZNm7DZbOzatavEx/3qq6949NFHy1qek4JCyJEjR+jcubNL36uyUQByc5dfbg6KBnPx1I8+srYeEZHKrm/fvqxdu5affvrpkufmzZtH69atadGiRYmPW6dOHQIDA11RYpHCw8Px8/OrkPfyVApAHqBLFxg61Nzu0wfS0qytR0SkMvvrX/9KnTp1mD9/vtP+rKwsli1bRt++ffntt9/o0aMHl19+OYGBgTRv3pzFixcXetw/XwL7/vvvuemmm/D39+eaa65h7dq1l7zmueee4+qrryYwMJAGDRowatQozp8/D5irsr/44ot888032Gw2bDabo+Y/XwLbvXs3t9xyCwEBAdSqVYtHH32UrKwsx/MPPfQQiYmJTJw4kYiICGrVqsWAAQMc71Ucdrudl156iSuuuAI/Pz9atmzJ6tWrHc+fO3eOgQMHEhERgb+/P9HR0YwfPx4AwzAYO3Ys9erVw8/Pj8jISJ588sliv3dpaCZoDzF+PPz73/D119CjB2zYYF4iExHxKIYBp09b896BgebaQ0Xw8fGhd+/ezJ8/n5EjR2L732uWLVtGbm4uPXr0ICsri1atWvHcc88RHBzMxx9/TK9evbjqqqto27Ztke9ht9u55557CAsL48svvyQjI8NpvFCeoKAg5s+fT2RkJLt37+aRRx4hKCiIZ599lqSkJPbs2cPq1atZt24dACEhIZccIzs7m4SEBOLi4vjqq684duwY/fr1Y+DAgU4hb/369URERLB+/Xp++OEHkpKSaNmyJY888kiR/QF4/fXXmTRpEjNnzuS6665j7ty53HnnnXz77bc0atSIN954g48++oj33nuPevXqkZaWRtr//kX/wQcfMHnyZJYsWUKzZs1IT0/nm2++Kdb7lpohl8jIyDAAIyMjw+pSnPzwg2EEBRkGGMbIkVZXIyJSuDNnzhj/+c9/jDNnzvyxMyvL/J+YFY+srGLXvnfvXgMw1q9f79h34403Gg8++GCBr+nSpYvx9NNPO77v0KGDMXjwYMf30dHRxuTJkw3DMIw1a9YYPj4+xs8//+x4/pNPPjEAY/ny5QW+x6uvvmq0atXK8f2YMWOMmJiYS9pdfJxZs2YZNWvWNLIu6v/HH39seHl5Genp6YZhGEZycrIRHR1tXLhwwdHm/vvvN5KSkgqs5c/vHRkZabz88stObdq0aWM88cQThmEYxqBBg4xbbrnFsNvtlxxr0qRJxtVXX22cO3euwPfLk+/P1f+U5O+3LoF5kKuuMhdNBfjb3yAlxdp6REQqqyZNmtCuXTvmzp0LwA8//MCmTZvo27cvALm5uYwbN47mzZtz2WWXUaNGDdasWcPhw4eLdfy9e/cSFRVFZGSkY19cXNwl7ZYuXUr79u0JDw+nRo0avPDCC8V+j4vfKyYmhurVqzv2tW/fHrvdzv79+x37mjVrhre3t+P7iIgIjh07Vqz3yMzM5JdffqF9+/ZO+9u3b8/evXsB8zLbzp07ady4MU8++SSffvqpo93999/PmTNnaNCgAY888gjLly/nwoULJepnSSkAeZikpD9Wi3/wQTh61OqKRERKIDDQnNvDikcJByD37duXDz74gFOnTjFv3jyuuuoqOnToAMCrr77K66+/znPPPcf69evZuXMnCQkJnDt3zmX/qVJTU+nZsyd33HEHK1euZMeOHYwcOdKl73GxatWqOX1vs9mw2+0uO/7111/PgQMHGDduHGfOnKFbt27cd999gLmI6/79+3nrrbcICAjgiSee4KabbirRGKSSUgDyQFOmQLNmkJ4OvXuDC38+RUTKl80G1atb8yjG+J+LdevWDS8vLxYtWsTbb7/Nww8/7BgPtHnzZu666y4efPBBYmJiaNCgAd99912xj920aVPS0tI4cuSIY98XX3zh1GbLli1ER0czcuRIWrduTaNGjTh06JBTG19fX3Jzc4t8r2+++YbsixaX3Lx5M15eXjRu3LjYNRcmODiYyMjIS1ai37x5M9dcc41Tu6SkJGbPns3SpUv54IMPOHHiBAABAQF07dqVN954gw0bNpCamsruclwVXAHIAwUGwtKlEBAAn34Kr75qdUUiIpVPjRo1SEpKYsSIERw5coSHHnrI8VyjRo1Yu3YtW7ZsYe/evTz22GMcLcEp+fj4eK6++mqSk5P55ptv2LRpEyNHjnRq06hRIw4fPsySJUv48ccfeeONN1i+fLlTm/r163PgwAF27tzJ8ePHyclnxtyePXvi7+9PcnIye/bsYf369QwaNIhevXoRFhZWsv8ohRg2bBivvPIKS5cuZf/+/QwfPpydO3cyePBgAF577TUWL17Mvn37+O6771i2bBnh4eGEhoYyf/585syZw549e/jvf//LwoULCQgIIDo62mX1/ZkCkIdq1sycFwhg5EhITbW2HhGRyqhv3778/vvvJCQkOI3XeeGFF7j++utJSEigY8eOhIeHk5iYWOzjenl5sXz5cs6cOUPbtm3p168fL7/8slObO++8k6eeeoqBAwfSsmVLtmzZwqi8NZL+595776VTp07cfPPN1KlTJ99b8QMDA1mzZg0nTpygTZs23Hfffdx6661MnTq1ZP8xivDkk08ydOhQnn76aZo3b87q1av56KOPaNSoEWDe0fb3v/+d1q1b06ZNGw4ePMiqVavw8vIiNDSU2bNn0759e1q0aMG6dev417/+Ra1atVxa48VshmEY5XZ0D5WZmUlISAgZGRkEBwdbXU6BDAMeeACWLIHoaNixA2rWtLoqERHT2bNnOXDgAFdeeSX+/v5WlyOVRGE/VyX5+60zQB7MZoOZM6FBAzh0CPr1M0ORiIiIFE4ByMMFB5vjgapVgw8/hOnTra5IRETE/SkAVQKtW8Mrr5jbQ4dCeU+eKSIi4ukUgCqJIUPgr3+FnBxzrqCLlngRERGRP1EAqiRsNpg3z1w9fv9+GDjQ6opEREy610ZcyVU/TwpAlUjt2rBoEXh5wYIF8M47VlckIlVZ3szCp61a/FQqpbyfpz/PXF1SWk+8krnpJhgzxnz07w9t24KLJvoUESkRb29vQkNDHetJBQYGOmZSFikpwzA4ffo0x44dIzQ01GndstJQAKqERo6EDRtg/Xro3t2cJFFTcIiIFcLDwwGKvaimSFFCQ0MdP1dloQBUCXl7w8KFEBMDO3fCsGHw5ptWVyUiVZHNZiMiIoK6deuW68KWUjVUq1atzGd+8igAVVKRkfD223DHHTB1KtxyC9x9t9VViUhV5e3t7bI/XCKuoEHQlVjnzvDMM+b2ww+bs0WLiIiImwSgadOmUb9+ffz9/YmNjWXr1q2Ftl+2bBlNmjTB39+f5s2bs2rVKqfnbTZbvo9Xq+Cy6S+/bA6EPnkSevQAnYEWERFxgwC0dOlShg4dypgxY9i+fTsxMTEkJCQUOGBuy5Yt9OjRg759+7Jjxw4SExNJTExkz549jjZHjhxxesydOxebzca9995bUd1yG76+5mKpwcHmYOgxY6yuSERExHqWrwYfGxtLmzZtmDp1KgB2u52oqCgGDRrE8OHDL2mflJREdnY2K1eudOy74YYbaNmyJTNmzMj3PRITEzl16hQpKSnFqslTVoMviWXLoFs3c8LENWvgttusrkhERMS1PGY1+HPnzrFt2zbi4+Md+7y8vIiPjyc1NTXf16Smpjq1B0hISCiw/dGjR/n444/p27dvgXXk5OSQmZnp9Khs7r8fHnvMXC3+wQchPd3qikRERKxjaQA6fvw4ubm5hIWFOe0PCwsjvYC/0Onp6SVqv2DBAoKCgrjnnnsKrGP8+PGEhIQ4HlFRUSXsiWeYPBmaN4djx6BXL7Dbra5IRETEGpaPASpvc+fOpWfPnvgXMhPgiBEjyMjIcDzS0tIqsMKKExAAS5dCYCCsW/fHCvIiIiJVjaUBqHbt2nh7e3P06FGn/UePHi1wlsfw8PBit9+0aRP79++nX79+hdbh5+dHcHCw06Oyatr0j0kRR42CzZutrUdERMQKlgYgX19fWrVq5TQ42W63k5KSQlxcXL6viYuLu2Qw89q1a/NtP2fOHFq1akVMTIxrC/dwffrAAw9Abq55a/yJE1ZXJCIiUrEsvwQ2dOhQZs+ezYIFC9i7dy/9+/cnOzubPn36ANC7d29GjBjhaD948GBWr17NpEmT2LdvH2PHjuXrr79m4MCBTsfNzMxk2bJlRZ79qYpsNpgxAxo2hLQ06NvXHBwtIiJSVVgegJKSkpg4cSKjR4+mZcuW7Ny5k9WrVzsGOh8+fJgjR4442rdr145FixYxa9YsYmJieP/991mxYgXXXnut03GXLFmCYRj06NGjQvvjKYKCzPFA1arBihUwbZrVFYmIiFQcy+cBckeVcR6ggrz+OgwZYk6Y+MUXcN11VlckIiJSOh4zD5BY78kn4c474dw5SEqCU6esrkhERKT8KQBVcTYbzJ0LV1wB338PAwZYXZGIiEj5UwASatWCxYvBywveeQcWLLC6IhERkfKlACQA/OUv8OKL5vYTT8C+fdbWIyIiUp4UgMRhxAi45RY4fdocD3TmjNUViYiIlA8FIHHw9oaFC6FOHdi1C555xuqKREREyocCkDiJiDDHAQG89RZ88IG19YiIiJQHBSC5REICPPusud23Lxw8aGk5IiIiLqcAJPn6v/+DG26AjAxzvbDz562uSERExHUUgCRf1aqZt8aHhpozRI8aZXVFIiIirqMAJAWqXx/+8Q9z+5VXYM0aS8sRERFxGQUgKdS990L//uZ2r15w0bq0IiIiHksBSIr02mvQogX8+is8+CDk5lpdkYiISNkoAEmR/P1h6VIIDITPPoMJE6yuSEREpGwUgKRYmjQx5wUCGD0aPv/c2npERETKQgFIii052RwHZLebt8b/9pvVFYmIiJSOApCUyLRp0KgR/PQTPPwwGIbVFYmIiJScApCUSFAQvPce+PrCRx/Bm29aXZGIiEjJKQBJibVsCZMmmdvDhsH27ZaWIyIiUmIKQFIqAwZAYiKcOwdJSXDqlNUViYiIFJ8CkJSKzQZz5kC9evDDD/D44xoPJCIinkMBSErtssvM9cK8vWHRIpg3z+qKREREikcBSMqkXTsYN87cHjgQ9u61th4REZHiUACSMnvuOYiPhzNnoFs386uIiIg7UwCSMvPygnfegbp1Yc8eeOopqysSEREpnAKQuER4OCxcaA6OnjkTli2zuiIREZGCKQCJy9x2Gwwfbm736wcHDlhbj4iISEEUgMSlXnzRHBidmQndu5vzBImIiLgbBSBxqWrVzFviQ0Nh61YYOdLqikRERC6lACQuFx39x5xAEyfCJ59YW4+IiMifKQBJuUhMNOcFAujdG375xdJyREREnCgASbl59VVz4dTjx+HBByE31+qKRERETApAUm78/WHpUqheHdavh5dftroiERERkwKQlKurr4bp083tF1+EjRutrUdERAQUgKQC9OoFyclgt0PPnuYlMRERESspAEmFmDoVGjeGn3+GPn3AMKyuSEREqjIFIKkQNWqY44H8/GDlSpgyxeqKRESkKlMAkgoTEwOvvWZuP/ccfP21tfWIiEjVpQAkFap/f7j3Xjh/HpKSzCUzREREKpoCkFQomw1mzzZni/7vf+GxxzQeSEREKp4CkFS4mjVh8WLw9oYlS2DOHKsrEhGRqkYBSCwRF/fHxIhPPgnffmttPSIiUrUoAIllhg2DhAQ4c8YcD3T6tNUViYhIVaEAJJbx8oK334bwcPMM0JAhVlckIiJVhQKQWKpuXVi48I/B0UuXWl2RiIhUBQpAYrlbb4Xnnze3H3kEfvzR2npERKTyUwAStzB2LPzlL3DqFHTvDufOWV2RiIhUZgpA4hZ8fGDRIrjsMnOG6BEjrK5IREQqMwUgcRtRUTBvnrn92mvw8cfW1iMiIpWXApC4lTvvNOcFAkhOhp9+srYeERGpnBSAxO38/e9w/fXw22/Qsyfk5lpdkYiIVDYKQOJ2/PzMJTJq1IB//xvGjbO6IhERqWwUgMQtNWoEM2ea2+PGwYYNlpYjIiKVjAKQuK0HHoA+fcBuN7d//dXqikREpLJQABK39uab0LQpHDliDoq2262uSEREKgMFIHFr1auby2P4+8Mnn8DkyVZXJCIilYECkLi95s1hyhRze/hw2LrV0nJERKQSUAASj/Doo3DffXDhgrlURkaG1RWJiIgnUwASj5C3Wnz9+nDggLloqmFYXZWIiHgqBSDxGKGh5nggHx9YtswMRCIiIqWhACQepW1bGD/e3B48GHbvtrYeERHxTApA4nGGDoXOneHsWUhKguxsqysSERFPowAkHsfLCxYsgIgI2Lv3j8VTRUREiksBSDxSnTrw7rvm4Oi5c2HRIqsrEhERT6IAJB7r5pth1Chz+7HH4IcfrK1HREQ8hwKQeLRRo+DGGyEryxwPlJNjdUUiIuIJLA9A06ZNo379+vj7+xMbG8vWIqb5XbZsGU2aNMHf35/mzZuzatWqS9rs3buXO++8k5CQEKpXr06bNm04fPhweXVBLOTjY17+qlULtm+H556zuiIREfEElgagpUuXMnToUMaMGcP27duJiYkhISGBY8eO5dt+y5Yt9OjRg759+7Jjxw4SExNJTExkz549jjY//vgjf/nLX2jSpAkbNmxg165djBo1Cn9//4rqllSwK66A+fPN7ddfh48+srQcERHxADbDsG4+3djYWNq0acPUqVMBsNvtREVFMWjQIIYPH35J+6SkJLKzs1m5cqVj3w033EDLli2ZMWMGAN27d6datWq88847pa4rMzOTkJAQMjIyCA4OLvVxpGINHWoulnrZZbBzJ0RFWV2RiIhUpJL8/bbsDNC5c+fYtm0b8fHxfxTj5UV8fDypqan5viY1NdWpPUBCQoKjvd1u5+OPP+bqq68mISGBunXrEhsby4oVKwqtJScnh8zMTKeHeJ7x46FVKzhxAh54wFw3TEREJD+WBaDjx4+Tm5tLWFiY0/6wsDDS09PzfU16enqh7Y8dO0ZWVhYTJkygU6dOfPrpp9x9993cc889bNy4scBaxo8fT0hIiOMRpVMHHsnPz1wqIygIPv8cXnzR6opERMRdWT4I2pXsdjsAd911F0899RQtW7Zk+PDh/PWvf3VcIsvPiBEjyMjIcDzS0tIqqmRxsauuglmzzO2XX4bPPrO2HhERcU+WBaDatWvj7e3N0aNHnfYfPXqU8PDwfF8THh5eaPvatWvj4+PDNddc49SmadOmhd4F5ufnR3BwsNNDPFf37tCvn7lafM+eUMCYehERqcIsC0C+vr60atWKlJQUxz673U5KSgpxcXH5viYuLs6pPcDatWsd7X19fWnTpg379+93avPdd98RHR3t4h6IO3v9dbjmGkhPh9694X8nB0VERADwsfLNhw4dSnJyMq1bt6Zt27ZMmTKF7Oxs+vTpA0Dv3r25/PLLGf+/5b8HDx5Mhw4dmDRpEl26dGHJkiV8/fXXzMq75gEMGzaMpKQkbrrpJm6++WZWr17Nv/71LzZs2GBFF8UigYHmeKA2bWDNGpg4EZ591uqqRETEbRgWe/PNN4169eoZvr6+Rtu2bY0vvvjC8VyHDh2M5ORkp/bvvfeecfXVVxu+vr5Gs2bNjI8//viSY86ZM8do2LCh4e/vb8TExBgrVqwoUU0ZGRkGYGRkZJSqT+I+Zs0yDDAMHx/DSE21uhoRESlPJfn7bek8QO5K8wBVHoYBPXqYZ4Pq14cdOyA01OqqRESkPHjEPEAiFcFmg5kzoUEDOHjwj8HRIiJStSkASaUXEgJLlkC1avDBB1DIjAgiIlJFKABJldCmDUyYYG4/9RTs2mVtPSIiYi0FIKkynnoKunSBnBxISoLsbKsrEhERqygASZVhs5mrxkdGwr59MHCg1RWJiIhVFICkSqldGxYtAi8vMwwtXGh1RSIiYgUFIKlyOnSA0aPN7ccfh+++s7YeERGpeApAUiW98AJ07GiOA+re3RwXJCIiVYcCkFRJ3t7w7rvmJbEdO2DYMKsrEhGRiqQAJFVWZCQsWGBuv/kmrFhhaTkiIlKBFICkSrvjDnj6aXP74Yfh8GFr6xERkYqhACRV3t/+Bm3bwu+/wwMPwIULVlckIiLlTQFIqjxfX1i8GIKDYfNmGDPG6opERKS8KQCJYC6WOnu2uT1+PKxbZ209IiJSvhSARP6nWzd49FFztfgHH4SjR62uSEREyosCkMhFpkyBa681w0/v3mC3W12RiIiUBwUgkYsEBMDSpebXTz+Fv//d6opERKQ8KACJ/Mk115jzAoE5Y/SWLdbWIyIirqcAJJKPhx+GHj0gN9f8euKE1RWJiIgrKQCJ5MNmgxkz4KqrzMkR+/UzB0eLiEjloAAkUoDgYHM8ULVqsHw5vPWW1RWJiIirKACJFKJVqz8GQg8dCjt3WlqOiIi4iAKQSBEGD4auXeHcOUhKgqwsqysSEZGyUgASKYLNBvPmwRVXwHffwYABVlckIiJlpQAkUgy1asGiReDlBW+/bT5ERMRzKQCJFNONN8LYseb2E0/A/v2WliMiImWgACRSAs8/D7fcAtnZ5tphZ89aXZGIiJSGApBICXh7w8KFUKcO7NoFzzxjdUUiIlIaCkAiJRQR8ccYoGnT4MMPra1HRERKrlQBKC0tjZ9++snx/datWxkyZAizZs1yWWEi7qxTJxg2zNzu2xcOHrS0HBERKaFSBaAHHniA9evXA5Cens5tt93G1q1bGTlyJC+99JJLCxRxVy+/DLGxcPKkuV7Y+fNWVyQiIsVVqgC0Z88e2rZtC8B7773Htddey5YtW3j33XeZP3++K+sTcVvVqsGSJRASAl98AaNHW12RiIgUV6kC0Pnz5/Hz8wNg3bp13HnnnQA0adKEI0eOuK46ETdXvz784x/m9oQJ8OmnlpYjIiLFVKoA1KxZM2bMmMGmTZtYu3YtnTp1AuCXX36hVq1aLi1QxN3ddx88/ri53asXpKdbW4+IiBStVAHolVdeYebMmXTs2JEePXoQExMDwEcffeS4NCZSlbz2GrRoAceOwYMPQm6u1RWJiEhhbIZhGKV5YW5uLpmZmdSsWdOx7+DBgwQGBlK3bl2XFWiFzMxMQkJCyMjIIDg42OpyxEPs22euHn/6tDlA+vnnra5IRKRqKcnf71KdATpz5gw5OTmO8HPo0CGmTJnC/v37PT78iJRWkybmvEBgDojevNnaekREpGClCkB33XUXb/9vJriTJ08SGxvLpEmTSExMZPr06S4tUMSTJCdDz57mJbAePeDECasrEhGR/JQqAG3fvp0bb7wRgPfff5+wsDAOHTrE22+/zRtvvOHSAkU8ic0G06dDo0aQlgZ9+kDpLjKLiEh5KlUAOn36NEFBQQB8+umn3HPPPXh5eXHDDTdw6NAhlxYo4mmCgmDpUvD1hY8+gqlTra5IRET+rFQBqGHDhqxYsYK0tDTWrFnD7bffDsCxY8c0aFgEuO46mDjR3H7mGdi+3dp6RETEWakC0OjRo3nmmWeoX78+bdu2JS4uDjDPBl133XUuLVDEUw0cCHfdBefOQVISnDpldUUiIpKn1LfBp6enc+TIEWJiYvDyMnPU1q1bCQ4OpkmTJi4tsqLpNnhxlRMnoGVLczxQz57wzjvmOCEREXG9kvz9LnUAypO3KvwVV1xRlsO4FQUgcaXNm6FDB/POsHnz4KGHrK5IRKRyKvd5gOx2Oy+99BIhISFER0cTHR1NaGgo48aNw263l6pokcqqfXt46SVze8AA2LvX2npERAR8SvOikSNHMmfOHCZMmED79u0B+Pzzzxk7dixnz57l5ZdfdmmRIp5u+HBYvx7WrTPHA335JQQEWF2ViEjVVapLYJGRkcyYMcOxCnyef/7znzzxxBP8/PPPLivQCroEJuUhPR1iYsz1wh5/3JwvSEREXKfcL4GdOHEi34HOTZo04YSmvhXJV3i4OQgaYMYMeP99a+sREanKShWAYmJimJrP7G5Tp06lRYsWZS5KpLK6/XbzchhAv35w4IC19YiIVFWlugS2ceNGunTpQr169RxzAKWmppKWlsaqVascy2R4Kl0Ck/J0/rx5V1hqKsTGwqZNUK2a1VWJiHi+cr8E1qFDB7777jvuvvtuTp48ycmTJ7nnnnv49ttveSfvHL+I5KtaNVi8GEJDzcHQI0daXZGISNVT5nmALvbNN99w/fXXk5ub66pDWkJngKQifPgh3Huvuf3JJ9Cpk7X1iIh4unI/AyQiZXfPPea8QAC9e8Mvv1hbj4hIVaIAJGKhiRPNW+N//RUefNCcLVpERMqfApCIhfz9YelSqF7dnCjxb3+zuiIRkaqhRDNB33PPPYU+f/LkybLUIlIlNW4Mb70Fyckwdqx5h9hNN1ldlYhI5VaiABQSElLk87179y5TQSJVUe/ekJICb78NDzwA33wDtWpZXZWISOXl0rvAKgvdBSZWyMqCVq3gu+/gr3+Fjz4Cm83qqkREPIfuAhPxQDVqmOOB/Pxg5Up4/XWrKxIRqbwUgETcSMuWMGmSuf3ss/D115aWIyJSaSkAibiZJ56Au+82l8zo3h0yM62uSESk8lEAEnEzNhvMmQP16sGPP8Ljj4NG6omIuJYCkIgbqlnTXC/M29v8Oneu1RWJiFQuCkAibqpdO/i//zO3Bw2Cb7+1th4RkcpEAUjEjT37LNx+O5w5A0lJ5lcRESk7BSARN+blZU6OGBZmngEaMsTqikREKge3CEDTpk2jfv36+Pv7Exsby9atWwttv2zZMpo0aYK/vz/Nmzdn1apVTs8/9NBD2Gw2p0enTp3Kswsi5SYsDBYuNAdHz5oF771ndUUiIp7P8gC0dOlShg4dypgxY9i+fTsxMTEkJCRw7NixfNtv2bKFHj160LdvX3bs2EFiYiKJiYns2bPHqV2nTp04cuSI47F48eKK6I5IuYiPhxEjzO1HHoH//tfaekREPJ3lS2HExsbSpk0bpk6dCoDdbicqKopBgwYxfPjwS9onJSWRnZ3NypUrHftuuOEGWrZsyYwZMwDzDNDJkydZsWJFsWrIyckhJyfH8X1mZiZRUVFaCkPcyoUL0LEjbN4MbdrA55+Dr6/VVYmIuA+PWQrj3LlzbNu2jfj4eMc+Ly8v4uPjSU1Nzfc1qampTu0BEhISLmm/YcMG6tatS+PGjenfvz+//fZbgXWMHz+ekJAQxyMqKqoMvRIpHz4+sGiReYv8V1/B889bXZGIiOeyNAAdP36c3NxcwsLCnPaHhYWRnp6e72vS09OLbN+pUyfefvttUlJSeOWVV9i4cSOdO3cmNzc332OOGDGCjIwMxyMtLa2MPRMpH/Xq/TEn0KRJ8PHH1tYjIuKpfKwuoDx0797dsd28eXNatGjBVVddxYYNG7j11lsvae/n54efn19FlihSaomJ5rxAb74JycnwzTdw+eVWVyUi4lksPQNUu3ZtvL29OXr0qNP+o0ePEh4enu9rwsPDS9QeoEGDBtSuXZsffvih7EWLuIFXX4XrroPffoOePaGAk5siIlIASwOQr68vrVq1IiUlxbHPbreTkpJCXFxcvq+Ji4tzag+wdu3aAtsD/PTTT/z2229ERES4pnARi/n5wdKlUKMGbNz4x4zRIiJSPJbfBj906FBmz57NggUL2Lt3L/379yc7O5s+ffoA0Lt3b0bk3f8LDB48mNWrVzNp0iT27dvH2LFj+frrrxk4cCAAWVlZDBs2jC+++IKDBw+SkpLCXXfdRcOGDUlISLCkjyLloVEjmD7d3H7pJTMIiYhI8Vg+BigpKYlff/2V0aNHk56eTsuWLVm9erVjoPPhw4fx8vojp7Vr145Fixbxwgsv8Pzzz9OoUSNWrFjBtddeC4C3tze7du1iwYIFnDx5ksjISG6//XbGjRuncT5S6Tz4IKSkwPz58MADsHMn1KljdVUiIu7P8nmA3FFJ5hEQsVp2NrRuDfv2wR13wMqV5qzRIiJVjcfMAyQiZVe9ujkeyM8PVq2CyZOtrkhExP0pAIlUAi1awJQp5vbw4eZEiSIiUjAFIJFK4rHH4N574fx5SEqCjAyrKxIRcV8KQCKVhM0G//gH1K8PBw7Ao4+CRviJiORPAUikEgkNhSVLzHXD3nvPDEQiInIpBSCRSiY2Fv72N3P7ySdhzx5r6xERcUcKQCKV0NNPQ0ICnD1rjgc6fdrqikRE3IsCkEgl5OUFb78NERHwn//A4MFWVyQi4l4UgEQqqbp1YeHCPwZHL1lidUUiIu5DAUikErvlFnjhBXP70Ufhhx+srUdExF0oAIlUcqNHw403wqlT0L075ORYXZGIiPUUgEQqOR8fWLQILrsMtm2DESOsrkhExHoKQCJVwBVXmCvGg7lW2MqVlpYjImI5BSCRKqJrVxgyxNxOToaffrK0HBERSykAiVQhEybA9dfDiRPwwANw4YLVFYmIWEMBSKQK8fODpUshKAg2bYKXXrK6IhERaygAiVQxDRvCzJnm9v/9H6xfb209IiJWUAASqYJ69IC+fc3V4nv2hGPHrK5IRKRiKQCJVFGvvw5Nm8KRI+agaLvd6opERCqOApBIFVW9Orz3Hvj7w+rVMGmS1RWJiFQcBSCRKuzaa80zQQDPPw9ffmltPSIiFUUBSKSKe+QR6NbNvCW+e3c4edLqikREyp8CkEgVZ7PBrFlw5ZVw8KAZiAzD6qpERMqXApCIEBICS5aY64a9//4ft8mLiFRWCkAiAkDbtuZM0WAumbFrl6XliIiUKwUgEXF46im44w7IyYGkJMjOtroiEZHyoQAkIg5eXuaq8ZGRsG8fDBpkdUUiIuVDAUhEnNSpA+++a4ahefPMbRGRykYBSEQu0bEjjBplbj/+OHz/vaXliIi4nAKQiORr1Cjo0AGyssz5gXJyrK5IRMR1FIBEJF/e3ublr1q1YPt2ePZZqysSEXEdBSARKdDll8OCBeb2G2/AP/9pbT0iIq6iACQiherSBYYONbf79IG0NGvrERFxBQUgESnS+PHQpg38/jv06GGuGyYi4skUgESkSL6+5lIZwcGweTOMHWt1RSIiZaMAJCLF0qCBuWgqwN/+BuvWWVuPiEhZKACJSLElJf2xWnyvXnD0qNUViYiUjgKQiJTIlCnQrBmkp0Pv3mC3W12RiEjJKQCJSIkEBsLSpRAQAJ9+Cq++anVFIiIlpwAkIiXWrJk5LxDAyJGQmmptPSIiJaUAJCKl0revuURGbq55a/zvv1tdkYhI8SkAiUip2GwwcyZcdRUcOgT9+pmDo0VEPIECkIiUWnCwOT9QtWrw4YcwfbrVFYmIFI8CkIiUSevW8Mor5vbQobBzp6XliIgUiwKQiJTZkCHw179CTo45Ligry+qKREQKpwAkImVms8G8eebq8fv3w8CBVlckIlI4BSARcYnatWHRIvDyggUL4J13rK5IRKRgCkAi4jI33QRjxpjb/fubZ4NERNyRApCIuNTIkXDzzZCdbY4HOnvW6opERC6lACQiLuXtDQsXQp065h1hw4ZZXZGIyKUUgETE5SIjzXFAAFOnwvLl1tYjIvJnCkAiUi46d4ZnnjG3H37YnC1aRMRdKACJSLl5+WVo2xZOnjTXCzt/3uqKRERMCkAiUm58fc2lMkJCzBXj8+4QExGxmgKQiJSrK6+E2bPN7QkTYO1aa+sREQEFIBGpAPffD489Zq4W/+CDkJ5udUUiUtUpAIlIhZg8GZo3h2PHoFcvsNutrkhEqjIFIBGpEAEBsHQpBAbCunV/rCAvImIFBSARqTBNm5rzAgGMGgWbN1tbj4hUXQpAIlKhHnoIHngAcnPNW+NPnLC6IhGpihSARKRC2WwwYwY0bAhpadC3rzk4WkSkIikAiUiFCwoyxwP5+sKKFTBtmtUViUhVowAkIpa4/np49VVz++mnYccOa+sRkapFAUhELDNoENx5J5w7B0lJcOqU1RWJSFWhACQilrHZYO5cuOIK+P57eOIJjQcSkYrhFgFo2rRp1K9fH39/f2JjY9m6dWuh7ZctW0aTJk3w9/enefPmrFq1qsC2jz/+ODabjSlTpri4ahFxhVq1YPFi8PaGhQvh7betrkhEqgLLA9DSpUsZOnQoY8aMYfv27cTExJCQkMCxY8fybb9lyxZ69OhB37592bFjB4mJiSQmJrJnz55L2i5fvpwvvviCyMjI8u6GiJTBX/4CL75obj/xBOzbZ209IlL52QzD2hPOsbGxtGnThqn/mx3NbrcTFRXFoEGDGD58+CXtk5KSyM7OZuXKlY59N9xwAy1btmTGjBmOfT///DOxsbGsWbOGLl26MGTIEIYMGVKsmjIzMwkJCSEjI4Pg4OCydVBEiiU3FxISICUFWrSAL74wZ48WESmukvz9tvQM0Llz59i2bRvx8fGOfV5eXsTHx5Oamprva1JTU53aAyQkJDi1t9vt9OrVi2HDhtGsWbMi68jJySEzM9PpISIVy9sb3nkH6tSBXbvMO8NERMqLpQHo+PHj5ObmEhYW5rQ/LCyM9AKWi05PTy+y/SuvvIKPjw9PPvlkseoYP348ISEhjkdUVFQJeyIirhARYYYggOnT4YMPrK1HRCovy8cAudq2bdt4/fXXmT9/PjabrVivGTFiBBkZGY5HWlpaOVcpIgVJSIDnnjO3+/aFgwctLUdEKilLA1Dt2rXx9vbm6NGjTvuPHj1KeHh4vq8JDw8vtP2mTZs4duwY9erVw8fHBx8fHw4dOsTTTz9N/fr18z2mn58fwcHBTg8Rsc64cXDDDZCRYa4Xdv681RWJSGVjaQDy9fWlVatWpKSkOPbZ7XZSUlKIi4vL9zVxcXFO7QHWrl3raN+rVy927drFzp07HY/IyEiGDRvGmjVryq8zIuIy1aqZt8aHhpqDoV94weqKRKSy8bG6gKFDh5KcnEzr1q1p27YtU6ZMITs7mz59+gDQu3dvLr/8csaPHw/A4MGD6dChA5MmTaJLly4sWbKEr7/+mlmzZgFQq1YtatWq5fQe1apVIzw8nMaNG1ds50Sk1OrXhzlz4N574e9/h1tuMS+PiYi4guVjgJKSkpg4cSKjR4+mZcuW7Ny5k9WrVzsGOh8+fJgjR4442rdr145FixYxa9YsYmJieP/991mxYgXXXnutVV0QkXJyzz3mvEAAvXrBRf8rEBEpE8vnAXJHmgdIxH2cPQuxseat8bfcAp9+at4yLyLyZx4zD5CISFH8/WHpUggMhM8+g/9dDRcRKRMFIBFxe02awFtvmdtjxsCmTdbWIyKeTwFIRDxCcrI5DshuhwcegN9+s7oiEfFkCkAi4jHeegsaNYKffoKHHwaNYBSR0lIAEhGPUaMGvPce+PrCRx/BG29YXZGIeCoFIBHxKC1bwqRJ5vawYbBtm6XliIiHUgASEY8zYADcfbe5REb37nDqlNUViYinUQASEY9js5mzRNerBz/8AI8/rvFAIlIyCkAi4pFq1jTXC/P2hkWLYN48qysSEU+iACQiHqtdO3PleICBA2HvXmvrERHPoQAkIh7tuefgttvgzBno1s38KiJSFAUgEfFoXl7wzjsQFgZ79sBTT1ldkYh4AgUgEfF4YWFmCLLZYOZMWLbM6opExN0pAIlIpXDbbTB8uLndrx8cOGBtPSLi3hSARKTSeOklc2B0ZqY5P9C5c1ZXJCLuSgGoIp09q/8ji5QjHx/z1vjQUNi6FUaOtLoiEXFXPlYXUKXMnWveqxsRAdHR5ixu0dHO2/XqQUiI1ZWKeKx69cw5ge6+GyZOhFtugc6dra5KRNyNAlBFSkszp6v95RfzkZqaf7uQEOdA9OeQFB5u3voiIvlKTDT/rTF1KvTuDTt3wuWXW12ViLgTm2FoAvk/y8zMJCQkhIyMDIKDg113YMOAY8fg0CE4fDj/rydOFH2catUgKqrgkFSvHvj7u65uEQ909izExZnhp2NHWLfOnDVaRCqvkvz9VgDKR7kFoOLIyio4HB0+DD/9BHZ70cepW/fSS2sXh6TLLjPvGRapxL77Dq6/HrKz4cUXYfRoqysSkfKkAFRGlgagoly4YF4+O3Qo/5B06BCcPl30capXvzQcXRySIiPNEaUiHu6dd8zLYF5e8Nln0KGD1RWJSHlRACojtw5ARTEM8zLaxYHozyHp2LGij+PtbQ6aKCgk1asHNWqUf39EXOChh2DBAjPXf/MN1K5tdUUiUh4UgMrIowNQcZw5Yw7ILigkpaXB+fNFH+eyywoOR9HR5mU4XWYTN5CVBa1bw/790KUL/Otf+tEUqYwUgMqo0gegouTmwtGjBV9iO3wYMjKKPo6fX+FnkKKiwNe3/PsjgnnmJzYWcnLg+efNhVOjo805g0SkclAAKqMqH4CKIyOj4MHahw7BkSPm5bjC2GzmnEiFhST9dRIXeustGDDAeV9w8KUzTVz8CAvTrBMinkIBqIwUgFzg3DnzjrXC7mg7e7bo4+T9dSooJIWH695mKTbDgPHj4cMPzR/D48eLfo2vb/73CeQ9rrhCJzJF3IUCUBkpAFUAw4Bffy18TqTffiv6ONWqmX+BCgpJ9epBQED590c8Una284nLix+HD8PPPxc964TNZg6uLuwsku4XEKkYCkBlpADkJrKyzAHZhc2JlJtb9HHq1Cl86ZFatTQiVvJ1/rwZggoKSIcOmWOKipJ3v0BBAal2bf0IiriCAlAZKQB5iAsXzLFG+Q3SztvOzi76OIGBhS89cvnlmhNJ8nXx5O4FBaSTJ4s+zsU/gvmFJE3LJVI8CkBlpABUSRgG/P57wXeyHTpk3u1WFC+v/OdEunhb1zikAJmZhQekI0eKPoa39x9XevMLSbrSK2JSACojBaAq5OxZ5zmR/hyS0tLMAd1FqVmz8KVH6tbVrUSSr5ycP6705heSijstV97qNwWdRQoN1WU2qfwUgMpIAUgc7Pai50QqzjUOPz9z3qPC5kTy8yv37ojnyc2F9PT8A1JJrvQGBV069ujikBQerowunk8BqIwUgKREMjMLv93/55+LnhMJCp8TKToaQkL0T3i5RN6V3sIus/36a9HH8fX9I6PnF5I0b6l4AgWgMlIAEpc6f77oOZHOnCn6OHn/hC8oJEVEaE4kydfp04Xf7v/TT8W73T8iovCzSEFBFdMfkYIoAJWRApBUKMMwZ+QrbE6k4szY5+NT9JxIgYHl3x/xOBcuFH27f3HmLc0bCldQSKpTRycxpXwpAJWRApC4nYv/CV/QnEgXLhR9nDp1Cl96RBPSSD4unre0oJD0++9FHycgIP95kDTjhLiKAlAZKQCJx8nN/WNOpIIGbGdlFX2cvAlpCgpJl19uzr4t8icXD4XLLyAVZ3lAb2/zR6yws0i63V8KowBURgpAUukYhnm3Wn5zIeV9TU8v+jheXuasfAXNqq2BIFKAnBzzRGVBAenw4eLd7p83sXtBIalmTZ3ErMoUgMpIAUiqpLwJaQq63f/w4eLNiRQaWvjSI1peXfJhtxd9u39xTmLWqFF4QIqI0I9fZaYAVEYKQCL5sNv/WPehoJBUnIEgF99vnV9I0pxIko+8k5iFjUM6dqzo41Srlv/t/pqSq3JQACojBSCRUjp1quDB2ocOwS+/FH2/NZiz8hW29IimNZZ8nDlT9O3+Ra2fbLOZP36FnUXSnwX3pQBURgpAIuUkb3n1wkJSceZEyrvOUVBIiozUnEhyiQsXzAxe2Fmk4vz45V3lLSgg1a2rfG4VBaAyUgASsYhhwG+/FT4nUnGmNb549dD87mgLDzcHa+uea7nIxVNyFRSQTpwo+jj+/vnf7p/30O3+5UcBqIwUgETc2OnTf6weml9ISksr3pxIYA72qFHDDEPF+VpUm8BA/dO/krv4Km9+AemXX4q+3d/Lq+Db/fMyuuYsLR0FoDJSABLxYH9ePTS/y2ynTpXPe9tsfwQlVwUrLcDlUc6dK/h2/0OHzHxenJspa9cuOCBFR+t2/4IoAJWRApBIJXfunHlP9alT5teLt4v6WtC+8vpfqa+vawNV9eq6D9xCdjscPVr47f7Fyec1ahR+ma2q3u6vAFRGCkAiUiJ2uzl61lWB6tQpc16m8lK9evEv6xWnja+vTke4UGG3+x86VPzb/fOGweX3qKy3+ysAlZECkIhY7vz5PwJSWYLUxV+LMwVBafj4lCxQFdW2enXdxVeIM2f+GAaX3ziktLSib/eHwm/3j472zNv9FYDKSAFIRCodwzD/croyUBXnnvHSCgws2Vmootr4+1eZs1S5uYXf7l/c2SZCQwu/zOaOt/srAJWRApCISDHk5ro2UJ06VbxTF6Xh7V3yQFVY2xo1PPZe9otnmyjoUZLb/QsKSVasnawAVEYKQCIiFjAMc+yTK4JUXtvs7PKr19+/5OOlCmsbEOA2p1Sysgq+3T9vUvfi3u5f2FkkV9/urwBURgpAIiKVRG6uOXdUWQLVn/cVZ9n60vDyKvyMU2nOVJXTKZjz5wu/3b84aycPGABTp7q2rpL8/fbM83ciIiLF4e1thoGgINcd89w51waqvGXu7XbIzDQfrlLQZJ+lPVNVvTrYbFSrBldeaT7yc/HayQU9oqNd183SUAASEREpCV9fqFXLfLiC3W6epXJloMqbRiEnx3z89ptrarXZnKdRKCBQedWoQXhQEOE1ahAbFAQNa8B1zm1zQy4DXBhMS0gBSERExEoXX/oKD3fNMfOmUXDl3FSGYT7y2pSR99NPw8SJLuhs6SgAiYiIVDbVqpnrZdSs6Zrj5U2jUNYzUxd/deVlyVJQABIREZHC2WzmLVuBgRAW5ppjWnwPVhVcKUREREQsZ/Et/wpAIiIiUuUoAImIiEiVowAkIiIiVY4CkIiIiFQ5CkAiIiJS5SgAiYiISJWjACQiIiJVjgKQiIiIVDluEYCmTZtG/fr18ff3JzY2lq1btxbaftmyZTRp0gR/f3+aN2/OqlWrnJ4fO3YsTZo0oXr16tSsWZP4+Hi+/PLL8uyCiIiIeBDLA9DSpUsZOnQoY8aMYfv27cTExJCQkMCxY8fybb9lyxZ69OhB37592bFjB4mJiSQmJrJnzx5Hm6uvvpqpU6eye/duPv/8c+rXr8/tt9/Or7/+WlHdEhERETdmMwxrF+OIjY2lTZs2TJ06FQC73U5UVBSDBg1i+PDhl7RPSkoiOzublStXOvbdcMMNtGzZkhkzZuT7HpmZmYSEhLBu3TpuvfXWS57PyckhJyfHqX1UVBQZGRkEBweXtYsiIiJSAfL+3hfn77elZ4DOnTvHtm3biI+Pd+zz8vIiPj6e1NTUfF+Tmprq1B4gISGhwPbnzp1j1qxZhISEEBMTk2+b8ePHExIS4nhERUWVskciIiLiCSwNQMePHyc3N5ewP60sGxYWRnp6er6vSU9PL1b7lStXUqNGDfz9/Zk8eTJr166ldu3a+R5zxIgRZGRkOB5paWll6JWIiIi4Ox+rCygvN998Mzt37uT48ePMnj2bbt268eWXX1K3bt1L2vr5+eHn5+f4Pu+qYGZmZoXVKyIiImWT93e7OKN7LA1AtWvXxtvbm6NHjzrtP3r0KOHh4fm+Jjw8vFjtq1evTsOGDWnYsCE33HADjRo1Ys6cOYwYMaLIuk6dOgWgS2EiIiIe6NSpU4SEhBTaxtIA5OvrS6tWrUhJSSExMREwB0GnpKQwcODAfF8TFxdHSkoKQ4YMcexbu3YtcXFxhb6X3W53GuhcmMjISNLS0ggKCsJmsxXrNcWVN8A6LS2tUg6wVv88X2Xvo/rn+Sp7H9W/0jMMg1OnThEZGVlkW8svgQ0dOpTk5GRat25N27ZtmTJlCtnZ2fTp0weA3r17c/nllzN+/HgABg8eTIcOHZg0aRJdunRhyZIlfP3118yaNQuA7OxsXn75Ze68804iIiI4fvw406ZN4+eff+b+++8vVk1eXl5cccUV5dPh/wkODq6UP9h51D/PV9n7qP55vsreR/WvdIo685PH8gCUlJTEr7/+yujRo0lPT6dly5asXr3aMdD58OHDeHn9MVa7Xbt2LFq0iBdeeIHnn3+eRo0asWLFCq699loAvL292bdvHwsWLOD48ePUqlWLNm3asGnTJpo1a2ZJH0VERMS9WD4PUFVTkjkKPJH65/kqex/VP89X2fuo/lUMy2eCrmr8/PwYM2aM011nlYn65/kqex/VP89X2fuo/lUMnQESERGRKkdngERERKTKUQASERGRKkcBSERERKocBSARERGpchSAyuDf//43Xbt2JTIyEpvNxooVK4p8zYYNG7j++uvx8/OjYcOGzJ8//5I206ZNo379+vj7+xMbG8vWrVtdX3wxlLR/H374Ibfddht16tQhODiYuLg41qxZ49Rm7Nix2Gw2p0eTJk3KsRcFK2n/NmzYcEntNpvtkoV43eXzg5L38aGHHsq3jxfPoeVOn+H48eNp06YNQUFB1K1bl8TERPbv31/k65YtW0aTJk3w9/enefPmrFq1yul5wzAYPXo0ERERBAQEEB8fz/fff19e3ShQafo3e/ZsbrzxRmrWrEnNmjWJj4+/5Gcwv8+5U6dO5dmVfJWmf/Pnz7+kdn9/f6c27vL5Qen62LFjx3x/D7t06eJo4y6f4fTp02nRooVjUsO4uDg++eSTQl/jLr9/CkBlkJ2dTUxMDNOmTStW+wMHDtClSxfHQq1DhgyhX79+TiFh6dKlDB06lDFjxrB9+3ZiYmJISEjg2LFj5dWNApW0f//+97+57bbbWLVqFdu2bePmm2+ma9eu7Nixw6lds2bNOHLkiOPx+eefl0f5RSpp//Ls37/fqf6LF9h1p88PSt7H119/3alvaWlpXHbZZZfMou4un+HGjRsZMGAAX3zxBWvXruX8+fPcfvvtZGdnF/iaLVu20KNHD/r27cuOHTtITEwkMTGRPXv2ONr8/e9/54033mDGjBl8+eWXVK9enYSEBM6ePVsR3XIoTf82bNhAjx49WL9+PampqURFRXH77bfz888/O7Xr1KmT02e4ePHi8u7OJUrTPzBnEL649kOHDjk97y6fH5Sujx9++KFT//bs2YO3t/clv4fu8BleccUVTJgwgW3btvH1119zyy23cNddd/Htt9/m296tfv8McQnAWL58eaFtnn32WaNZs2ZO+5KSkoyEhATH923btjUGDBjg+D43N9eIjIw0xo8f79J6S6o4/cvPNddcY7z44ouO78eMGWPExMS4rjAXKU7/1q9fbwDG77//XmAbd/38DKN0n+Hy5csNm81mHDx40LHPXT9DwzCMY8eOGYCxcePGAtt069bN6NKli9O+2NhY47HHHjMMwzDsdrsRHh5uvPrqq47nT548afj5+RmLFy8un8KLqTj9+7MLFy4YQUFBxoIFCxz7kpOTjbvuuqscKiyb4vRv3rx5RkhISIHPu/PnZxil+wwnT55sBAUFGVlZWY597voZGoZh1KxZ0/jHP/6R73Pu9PunM0AVKDU1lfj4eKd9CQkJpKamAnDu3Dm2bdvm1MbLy4v4+HhHG09it9s5deoUl112mdP+77//nsjISBo0aEDPnj05fPiwRRWWTsuWLYmIiOC2225j8+bNjv2V7fMDmDNnDvHx8URHRzvtd9fPMCMjA+CSn7mLFfV7eODAAdLT053ahISEEBsba/nnWJz+/dnp06c5f/78Ja/ZsGEDdevWpXHjxvTv35/ffvvNpbWWRnH7l5WVRXR0NFFRUZecbXDnzw9K9xnOmTOH7t27U716daf97vYZ5ubmsmTJErKzswtcoNydfv8UgCpQenq6Y42zPGFhYWRmZnLmzBmOHz9Obm5uvm3+PM7EE0ycOJGsrCy6devm2BcbG8v8+fNZvXo106dP58CBA9x4442cOnXKwkqLJyIighkzZvDBBx/wwQcfEBUVRceOHdm+fTtApfv8fvnlFz755BP69evntN9dP0O73c6QIUNo3769Y23A/BT0e5j3GeV9dbfPsbj9+7PnnnuOyMhIpz8onTp14u233yYlJYVXXnmFjRs30rlzZ3Jzc8uj9GIpbv8aN27M3Llz+ec//8nChQux2+20a9eOn376CXDfzw9K9xlu3bqVPXv2XPJ76E6f4e7du6lRowZ+fn48/vjjLF++nGuuuSbftu70+2f5YqhSOS1atIgXX3yRf/7zn05jZDp37uzYbtGiBbGxsURHR/Pee+/Rt29fK0ottsaNG9O4cWPH9+3atePHH39k8uTJvPPOOxZWVj4WLFhAaGgoiYmJTvvd9TMcMGAAe/bssWw8UnkrTf8mTJjAkiVL2LBhg9NA4e7duzu2mzdvTosWLbjqqqvYsGEDt956q0vrLq7i9i8uLs7p7EK7du1o2rQpM2fOZNy4ceVdZpmU5jOcM2cOzZs3p23btk773ekzbNy4MTt37iQjI4P333+f5ORkNm7cWGAIchc6A1SBwsPDOXr0qNO+o0ePEhwcTEBAALVr18bb2zvfNuHh4RVZapksWbKEfv368d57711yqvPPQkNDufrqq/nhhx8qqDrXatu2raP2yvL5gXkXxty5c+nVqxe+vr6FtnWHz3DgwIGsXLmS9evXc8UVVxTatqDfw7zPKO+rO32OJelfnokTJzJhwgQ+/fRTWrRoUWjbBg0aULt2bcs+w9L0L0+1atW47rrrHLW74+cHpetjdnY2S5YsKdY/LKz8DH19fWnYsCGtWrVi/PjxxMTE8Prrr+fb1p1+/xSAKlBcXBwpKSlO+9auXev414yvry+tWrVyamO320lJSSnweqq7Wbx4MX369GHx4sVOt2wWJCsrix9//JGIiIgKqM71du7c6ai9Mnx+eTZu3MgPP/xQrP/xWvkZGobBwIEDWb58OZ999hlXXnllka8p6vfwyiuvJDw83KlNZmYmX375ZYV/jqXpH5h30YwbN47Vq1fTunXrItv/9NNP/PbbbxX+GZa2fxfLzc1l9+7djtrd6fODsvVx2bJl5OTk8OCDDxbZ1qrPMD92u52cnJx8n3Or3z+XDqmuYk6dOmXs2LHD2LFjhwEYr732mrFjxw7j0KFDhmEYxvDhw41evXo52v/3v/81AgMDjWHDhhl79+41pk2bZnh7exurV692tFmyZInh5+dnzJ8/3/jPf/5jPProo0ZoaKiRnp7u9v179913DR8fH2PatGnGkSNHHI+TJ0862jz99NPGhg0bjAMHDhibN2824uPjjdq1axvHjh1z+/5NnjzZWLFihfH9998bu3fvNgYPHmx4eXkZ69atc7Rxp8/PMErexzwPPvigERsbm+8x3ekz7N+/vxESEmJs2LDB6Wfu9OnTjja9evUyhg8f7vh+8+bNho+PjzFx4kRj7969xpgxY4xq1aoZu3fvdrSZMGGCERoaavzzn/80du3aZdx1113GlVdeaZw5c8bt+zdhwgTD19fXeP/9951ec+rUKcMwzJ+JZ555xkhNTTUOHDhgrFu3zrj++uuNRo0aGWfPnnX7/r344ovGmjVrjB9//NHYtm2b0b17d8Pf39/49ttvHW3c5fMzjNL1Mc9f/vIXIykp6ZL97vQZDh8+3Ni4caNx4MABY9euXcbw4cMNm81mfPrpp4ZhuPfvnwJQGeTdFv3nR3JysmEY5m2KHTp0uOQ1LVu2NHx9fY0GDRoY8+bNu+S4b775plGvXj3D19fXaNu2rfHFF1+Uf2fyUdL+dejQodD2hmHe9h8REWH4+voal19+uZGUlGT88MMPFdux/ylp/1555RXjqquuMvz9/Y3LLrvM6Nixo/HZZ59dclx3+fwMo3Q/oydPnjQCAgKMWbNm5XtMd/oM8+sb4PR71aFDB6efQcMwjPfee8+4+uqrDV9fX6NZs2bGxx9/7PS83W43Ro0aZYSFhRl+fn7Grbfeauzfv78CeuSsNP2Ljo7O9zVjxowxDMMwTp8+bdx+++1GnTp1jGrVqhnR0dHGI488YklIL03/hgwZ4vj9CgsLM+644w5j+/btTsd1l8/PMEr/M7pv3z4DcASJi7nTZ/jwww8b0dHRhq+vr1GnTh3j1ltvdarZnX//bIZhGC46mSQiIiLiETQGSERERKocBSARERGpchSAREREpMpRABIREZEqRwFIREREqhwFIBEREalyFIBERESkylEAEhERkSpHAUhEpAA2m40VK1ZYXYaIlAMFIBFxSw899BA2m+2SR6dOnawuTUQqAR+rCxARKUinTp2YN2+e0z4/Pz+LqhGRykRngETEbfn5+REeHu70qFmzJmBenpo+fTqdO3cmICCABg0a8P777zu9fvfu3dxyyy0EBARQq1YtHn30UbKyspzazJ07l2bNmuHn50dERAQDBw50ev748ePcfffdBAYG0qhRIz766CPHc7///js9e/akTp06BAQE0KhRo0sCm4i4JwUgEfFYo0aN4t577+Wbb76hZ8+edO/enb179wKQnZ1NQkICNWvW5KuvvmLZsmWsW7fOKeBMnz6dAQMG8Oijj7J7924++ugjGjZs6PQeL774It26dWPXrl3ccccd9OzZkxMnTjje/z//+Q+ffPIJe/fuZfr06dSuXbvi/gOISOm5fH15EREXSE5ONry9vY3q1as7PV5++WXDMAwDMB5//HGn18TGxhr9+/c3DMMwZs2aZdSsWdPIyspyPP/xxx8bXl5eRnp6umEYhhEZGWmMHDmywBoA44UXXnB8n5WVZQDGJ598YhiGYXTt2tXo06ePazosIhVKY4BExG3dfPPNTJ8+3WnfZZdd5tiOi4tzei4uLo6dO3cCsHfvXmJiYqhevbrj+fbt22O329m/fz82m41ffvmFW2+9tdAaWrRo4diuXr06wcHBHDt2DID+/ftz7733sn37dm6//XYSExNp165dqfoqIhVLAUhE3Fb16tUvuSTlKgEBAcVqV61aNafvbTYbdrsdgM6dO3Po0CFWrVrF2rVrufXWWxkwYAATJ050eb0i4loaAyQiHuuLL7645PumTZsC0LRpU7755huys7Mdz2/evBkvLy8aN25MUFAQ9evXJyUlpUw11KlTh+TkZBYuXMiUKVOYNWtWmY4nIhVDZ4BExG3l5OSQnp7utM/Hx8cx0HjZsmW0bt2av/zlL7z77rts3bqVOXPmANCzZ0/GjBlDcnIyY8eO5ddff2XQoEH06tWLsLAwAMaOHcvjjz9O3bp16dy5M6dOnWLz5s0MGjSoWPWNHj2aVq1a0axZM3Jycli5cqUjgImIe1MAEhG3tXr1aiIiIpz2NW7cmH379gHmHVpLlizhiSeeICIigsWLF3PNNdcAEBgYyJo1axg8eDBt2rQhMDCQe++9l9dee81xrOTkZM6ePcvkyZN55plnqF27Nvfdd1+x6/P19WXEiBEcPHiQgIAAbrzxRpYsWeKCnotIebMZhmFYXYSISEnZbDaWL19OYmKi1aWIiAfSGCARERGpchSAREREpMrRGCAR8Ui6ei8iZaEzQCIiIlLlKACJiIhIlaMAJCIiIlWOApCIiIhUOQpAIiIiUuUoAImIiEiVowAkIiIiVY4CkIiIiFQ5/w9jjD+lSRTPRgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'NLP_project_checkpoint.pt')"
      ],
      "metadata": {
        "id": "kF_-Ilpa8qGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('NLP_project_checkpoint.pt')"
      ],
      "metadata": {
        "id": "_SfFs9IceQcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()                                                               # switch the model to evaluation mode\n",
        "\n",
        "valid_token_ids, valid_masks, valid_preds = [], [], []\n",
        "                                                \n",
        "with torch.no_grad():                                                      # temporarily disable gradient calculations within the for loop\n",
        "    for step3, batch_data3 in enumerate(tqdm(valid_dataloader)):\n",
        "        valid_tokens_batch, valid_masks_batch, valid_labels_batch = tuple(t.to(device) for t in batch_data3)\n",
        "        valid_labels_batch = valid_labels_batch.unsqueeze(-1)\n",
        "        _, valid_output = model(valid_tokens_batch, valid_masks_batch, valid_labels_batch)\n",
        "        valid_token_ids.append(valid_tokens_batch)\n",
        "        valid_masks.append(valid_masks_batch)\n",
        "        valid_preds.append(valid_output[:, :, 0])\n",
        "\n",
        "valid_token_ids = torch.cat(valid_token_ids, dim=0).tolist()\n",
        "valid_masks = torch.cat(valid_masks, dim=0).tolist()\n",
        "valid_preds = torch.cat(valid_preds, dim=0).tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvGuo1kVCDCU",
        "outputId": "cfa0bf79-efc9-4b0e-8066-a6ed611a419c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:25<00:00,  5.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()                                                         # switch the model to evaluation mode\n",
        "\n",
        "test_tokens_ids, test_masks, test_preds = [], [], []\n",
        "\n",
        "with torch.no_grad():                                                # temporarily disable gradient calculations within the for loop\n",
        "    for step, batch_data in enumerate(tqdm(test_dataloader)):\n",
        "        token_ids, masks = tuple(t.to(device) for t in batch_data)\n",
        "        _, output = model(token_ids, masks)\n",
        "        test_tokens_ids += token_ids.tolist()\n",
        "        test_masks += masks.tolist()\n",
        "        test_preds += output[:, :, 0].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KayB6As3SLbf",
        "outputId": "f3a5e7a7-3090-458a-8da8-151266b721dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:44<00:00,  5.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "def threshold_fun(preds, threshold):\n",
        "    # testy_preds = []\n",
        "    # for i in test_preds:\n",
        "    #     testy_preds.append(np.mean(i))         # converting the predicted values into binary values given a threshold\n",
        "    pred = copy.deepcopy(preds)\n",
        "    for i in range(len(pred)):\n",
        "        for j in range(len(pred[0])):\n",
        "          if pred[i][j] >= threshold:\n",
        "              pred[i][j] = 1\n",
        "          else:\n",
        "              pred[i][j] = 0\n",
        "    return pred"
      ],
      "metadata": {
        "id": "trGwnHbLIjfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_pred = threshold_fun(valid_preds, 0.6)"
      ],
      "metadata": {
        "id": "wAjDAUo3aVNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def truncated(preds, masks): \n",
        "  new_preds = []\n",
        "  for pr, ma in zip(preds, masks):\n",
        "    pr = [pr[i] for i in range(len(pr)) if ma[i]==1]   #truncate\n",
        "    new_preds.append(pr)\n",
        "  return new_preds"
      ],
      "metadata": {
        "id": "MPxjmMyrRiTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_new_labels = truncated(valid_labels, valid_masks)\n",
        "valid_new_preds = truncated(valid_pred, valid_masks)"
      ],
      "metadata": {
        "id": "jDX_VF7CvOEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id_2_tokens(token_ids):\n",
        "    id2token=[]\n",
        "    for i in range(len(token_ids)):\n",
        "        id2token.append(tokenizer.convert_ids_to_tokens(token_ids[i]))\n",
        "    return id2token"
      ],
      "metadata": {
        "id": "_Lbdb68Md6AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_tokens_new = id_2_tokens(valid_token_ids)"
      ],
      "metadata": {
        "id": "vFAdr7Jyd6Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def toxic_tokens(tokens, predicts, texts):\n",
        "    final_toxic_tokens = []\n",
        "    for (token, pred, text) in zip(tokens, predicts, texts):\n",
        "        toxic_tokens_spans = []\n",
        "        start = 0\n",
        "        for i in range(len(token)):\n",
        "            tk = token[i].strip('#')\n",
        "            start = text.find(tk,start)\n",
        "            end = start + len(tk)\n",
        "            if pred[i] == 1 and start!=-1:\n",
        "                toxic_tokens_spans.extend(range(start,end))\n",
        "            start=end\n",
        "        final_toxic_tokens.append(toxic_tokens_spans)\n",
        "    return final_toxic_tokens"
      ],
      "metadata": {
        "id": "LypRU2v6l2nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_toxic_tokens = toxic_tokens(valid_tokens, valid_new_preds, valid_text)"
      ],
      "metadata": {
        "id": "iBq363desvV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(ground_truth, prediction):\n",
        "    \n",
        "    #Calculates F1 score for a set of spans\n",
        "    true_positives = 0\n",
        "    if len(ground_truth) == 0 and len(prediction) == 0:\n",
        "        return 1.0\n",
        "    elif len(ground_truth) == 0 and len(prediction) != 0:\n",
        "        return 0.0\n",
        "    elif len(ground_truth) != 0 and len(prediction) == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        true_positives_set = set(ground_truth).intersection(set(prediction))\n",
        "        true_positives_len = len(true_positives_set)\n",
        "\n",
        "        pred_cardinal = len(prediction)\n",
        "        grou_cardinal = len(ground_truth)\n",
        "        precision = true_positives_len / pred_cardinal\n",
        "        recall = true_positives_len / grou_cardinal\n",
        "        if precision + recall == 0:\n",
        "            return 0.0\n",
        "        else:\n",
        "            f1_score = 2 * precision * recall / (precision + recall)\n",
        "            return f1_score"
      ],
      "metadata": {
        "id": "51_aYt7jyT95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_valid = []\n",
        "for i in range(len(valid_toxic_tokens)):\n",
        "    f1_score_valid.append(f1_score(valid_spans[i], valid_toxic_tokens[i]))\n",
        "print(np.mean(f1_score_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVu5B5QZOFvS",
        "outputId": "f6842239-10ef-41fb-9d48-df638a3a8487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5929392703873725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i8wYnTvETU0L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}